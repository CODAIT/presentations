{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning and Model Evaluations on Fashion-MNIST Dataset\n",
    "\n",
    "\n",
    "In this notebook we will use the [Keras deep learning Python library](https://keras.io/) to build and train a model that can be used to identify and classify fashion and clothing items.\n",
    "\n",
    "\n",
    "### Table of Contents:\n",
    "* [0. Prerequisites](#cell0)\n",
    "* [1. Read Data](#cell1)\n",
    "* [2. Prepare the Data For Training](#cell2)\n",
    "* [3. Build the Model](#cell3)\n",
    "* [4. Train the Model](#cell4)\n",
    "* [5. Test and Evaluate Model Performance](#cell5)\n",
    "* [Authors](#authors)\n",
    "\n",
    "\n",
    "#### Import required packages\n",
    "\n",
    "Install and import the required packages, including `pandas`, `matplotlib`, `tensorflow`, `numpy`, `sklearn` and `seaborn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define required imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cell1\"></a>\n",
    "\n",
    "### 1. Read Data\n",
    "\n",
    "1. Download data \n",
    "2. Read in training data from `fashion-mnist_train.csv` and test data from `fashion-mnist_test.csv` into arrays. Each row contains a class label and pixel data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://dax-cdn.cdn.appdomain.cloud/dax-fashion-mnist/1.0.2/fashion-mnist.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xzvf fashion-mnist.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training data\n",
    "data = pd.read_csv('fashion-mnist_train.csv').values\n",
    "print('Loaded {} data rows from {}.'.format(len(data), 'fashion-mnist_train.csv'))\n",
    "\n",
    "# load test data into an array\n",
    "test_data = pd.read_csv('fashion-mnist_test.csv').values\n",
    "print('Loaded {} data rows from {}.'.format(len(test_data), 'fashion-mnist_test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cell2\"></a>\n",
    "\n",
    "### 2. Prepare the Data For Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process item labels\n",
    "\n",
    "Each row in the training and test dataset files contains a label that identifies the clothing item that is depicted by the pixel data. The label is expressed as a number between 0 and 9, and mapped as follows:\n",
    "\n",
    "- 0 - T-shirt/top\n",
    "- 1 - Trouser \n",
    "- 2 - Pullover\n",
    "- 3 - Dress  \n",
    "- 4 - Coat  \n",
    "- 5 - Sandal  \n",
    "- 6 - Shirt  \n",
    "- 7 - Sneaker  \n",
    "- 8 - Bag  \n",
    "- 9 - Ankle boot \n",
    "\n",
    "We start by defining a simple mapping between the label number and a textual description, which we'll use to make the output more reader-friendly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define simple label lookup used to display user-friendly labels\n",
    "label_map = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the labels for each image in the dataset, which is the first value in each row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the label of each picture\n",
    "Y_train = data[:,0]\n",
    "\n",
    "# display first label for illustrative purposes\n",
    "print('Label: {} (\"{}\")'.format(Y_train[0], label_map[Y_train[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use scikit-learn's [`sklearn.preprocessing.LabelBinarizer`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html) to binarize the labels in a [one-vs-all](https://en.wikipedia.org/wiki/Multiclass_classification#One-vs.-rest) fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the labels into binary forms\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "label_data = lb.fit_transform(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each label is now transformed into an array of 0s and 1s, as shown in the example below for the first row in the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display first encoded label for illustrative purposes\n",
    "print('Label: {} (\"{}\") Binary label: {}'.format(Y_train[0], label_map[Y_train[0]], label_data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure that there are no unexpected labels in the training dataset file. The output should only list the numbers 0 through 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lb.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process pixel data\n",
    "\n",
    "\n",
    "As we've discussed in the first notebook when we explored the dataset, the grayscale clothing images are 28px by 28px images in size (for a total of 784) and encoded as pixel values.\n",
    "Extract the pixel values and store them in a Numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[:, 1:].reshape(data.shape[0],28, 28, 1).astype( 'float32' )\n",
    "print('Training data shape', X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pixel data in each row contain brightness information for each pixel in the 28x28 grayscale image. The pixel brightness is stored as an 8-bit integer, ranging from 0 (typically representing black) to 255 (white). Values in between represent different shades of gray. To normalize the values, we therefore need to divide each pixel data value by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = X_train/ 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cell3\"></a>\n",
    "### 3. Build the Model\n",
    "\n",
    "Keras is a high-level neural networks API that can run on top of [TensorFlow](https://www.tensorflow.org/), the [Microsoft Cognitive Toolkit (CNTK)](https://docs.microsoft.com/en-us/cognitive-toolkit/), or [Theano](http://www.deeplearning.net/software/theano/). In this notebook we will utilize the Tensorflow [`tf.keras`](https://www.tensorflow.org/api_docs/python/tf/keras) module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Keras, you assemble layers to build models. A model is usually a graph of layers. The most common type of model is a stack of layers: the [`tf.keras.Sequential`](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up the layers\n",
    "\n",
    "The basic building block of a neural network constitutes multiple layers. Layers extract representations from the data fed into them. Generally, most deep learning models consist of multiple simple layers which are chained together. We use three basic layers as building blocks for our classifier - convolution layer, max pooling layer, and dense layer. These building blocks are common starting points for solving vision problems using deep learning as evidenced by their usage in almost all modern day peer to peer publications in this field.\n",
    "\n",
    "It is beyond the scope of this notebook to explain the chosen [layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers) and how to tune the hyper parameters to improve performance. Simplified speaking, the model extracts features from the image using convolutional and pooling layers and classifies the object using the dense softmax layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a 2D convolution layer with 64 units to the model\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) \n",
    "# Add a max pooling operation for spatial data\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "# Add a 2D convolution layer with 32 units to the model\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "# Add a max pooling operation for spatial data\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "# Add a flattened input layer\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "# Add a densely-connected layer with 256 units to the model:\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "# Add a layer that applies Dropout to the input\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "# Add a softmax layer with 10 output units:\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the model summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cell4\"></a>\n",
    "### 4. Train the Model\n",
    "\n",
    "Now that we've created the model we need to configure it for training.\n",
    "\n",
    "#### Configure model training\n",
    "\n",
    "\n",
    "Let's first define the terms _loss function_ and _accuracy metric_.\n",
    "\n",
    "A loss function is used to optimize a machine learning algorithm. The loss is calculated on training and validation and its interpretation is based on how well the model is doing in these two sets. It is the sum of errors made for each example in training or validation sets. Loss value implies how poorly or well a model behaves after each iteration of optimization. \n",
    "\n",
    "In this notebook we choose [categorial_crossentropy](https://gombru.github.io/2018/05/23/cross_entropy_loss/) as loss function, which is best suited for multi-class classification. \n",
    "\n",
    "An accuracy metric is used to measure the algorithm’s performance in an interpretable way. Accuracy of a model is usually determined after the model parameters and is calculated in the form of a percentage. It is the measure of how accurate your model's prediction is compared to the true data. <br>\n",
    "\n",
    "While there are many optimizers for the gradient descent and most of them would do the job, we choose the [Adam algorithm](http://arxiv.org/abs/1412.6980) as it appears to be the most common across common deep learning implementations for such tasks. During training and testing the _accuracy_ metrics will be evaluated. \n",
    "\n",
    "For information about additional configuration options and details refer to the [`model.compile()`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile) documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model\n",
    "\n",
    "We train the model by calling [`model.fit()`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit). As input we pass the prepared training data, reserving 33% of the training data for validation, limit training to 5 epochs (an iteration over the entire training data) and use a batch size of 100.\n",
    "\n",
    "Using this configuration model training should take a couple of minutes. While training is in progress the training time, loss and accuracy metrics are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed input data and label data into the model and save it\n",
    "training_history = model.fit(input_data, \n",
    "                             label_data, \n",
    "                             validation_split=0.33,\n",
    "                             epochs=5,\n",
    "                             batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see how over time loss decreases and accuracy increases. Running training for 5 epochs, the final accuracy is close to 90%.\n",
    "\n",
    "If you'd like you can change the number of epochs and batch size to observe how accuracy changes. For example increasing the number of epochs to 10 should give you more accurate results! \n",
    "> Keep in mind that training time will increase and more resources will be required to complete the job. \n",
    "\n",
    "The `model.fit()` method returns an object that contains a record of loss values and metrics values (which based on our training configuration is `accuracy`) for training and validation for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it easier to review the results we plot loss and accuracy for each epoch using the [matplotlib](https://matplotlib.org/) visualization library. The history for the validation dataset is labeled as `validation` and the history of training dataset is labeled as `train`.\n",
    "\n",
    "> Note that your graphs might look slightly different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = len(training_history.history.get('loss',[]))\n",
    "\n",
    "# Draw Model Accuracy\n",
    "plt.figure(2,figsize=(6,4))\n",
    "plt.plot(range(epoch),training_history.history['acc'])\n",
    "plt.plot(range(epoch),training_history.history['val_acc'])\n",
    "plt.xlabel('# Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend(['train','validation'],loc=4)\n",
    "plt.style.use(['classic'])\n",
    "\n",
    "# Draw Model Loss\n",
    "plt.figure(1,figsize=(6,4))\n",
    "plt.plot(range(epoch),training_history.history['loss'])\n",
    "plt.plot(range(epoch),training_history.history['val_loss'])\n",
    "plt.xlabel('# Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.grid(True)\n",
    "plt.legend(['train','validation'])\n",
    "plt.style.use(['classic'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model accuracy should increase with each epoch and loss decrease. Do note though that you might observe that [overfitting](https://en.wikipedia.org/wiki/Overfitting) has occured if accuracy drops and the loss increases for the validation data, whereas it improves for the training data.\n",
    "\n",
    "### Save the model\n",
    "\n",
    "You can save the trained model for later re-use in a file using [`model.save()`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#save). The saved file includes\n",
    "- the model architecture, which allows for re-instantiation of the model\n",
    "- the model weights\n",
    "- the optimizer state, which allows for resuming of the training where you left off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use save function to export model\n",
    "model.save('fashion_mnist.h5')\n",
    "# model.save('fashion_mnist.h5', save_format='h5') # TensorFlow 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czvf assets.tar.gz fashion_mnist.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save trained model back to the Watson Studio project storage\n",
    "\n",
    "If you are using Watson Studio project to run the notebook, uncomment the below cell to save the model back to the project storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert a project token\n",
    "\n",
    "\n",
    "If you do not see the cell above, follow these steps to enable the notebook to access the dataset from the project's resources:\n",
    "\n",
    "* Click on `More -> Insert project token` in the top-right menu section\n",
    "\n",
    "![ws-project.mov](https://media.giphy.com/media/jSVxX2spqwWF9unYrs/giphy.gif)\n",
    "\n",
    "* This should insert a cell at the top of this notebook similar to the example given above.\n",
    "\n",
    "  > If an error is displayed indicating that no project token is defined, follow [these instructions](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/token.html?audience=wdp&context=data).\n",
    "\n",
    "* Run the newly inserted cell before proceeding with the notebook execution below"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Save to the project\n",
    "with open('assets.tar.gz', mode='rb') as file: \n",
    "    fileContent = file.read()\n",
    "    project.save_data(file_name = \"assets.tar.gz\",data=fileContent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cell5\"></a>\n",
    "### 5. Test and Evaluate Model Performance\n",
    "\n",
    "Now that we've trained the model it is time to test how accurate its predictions are for the unseen data in `fashion-mnist_test.csv`.\n",
    "We'll:\n",
    "- Prepare the test data\n",
    "- Run predictions on the test data\n",
    "- Sample the prediction results\n",
    "- Calculate and visualize model performance metrics\n",
    "\n",
    "\n",
    "#### Prepare the Test Data\n",
    "\n",
    "Prepare the test data like we've done earlier with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data points from pixels to weighted values\n",
    "X_test = test_data[:, 1:].reshape(test_data.shape[0],28, 28, 1).astype( 'float32' )\n",
    "test_input_data = X_test/ 255.0\n",
    "\n",
    "# Save the actual label of the test data - we can call it 'correct answer'\n",
    "label = test_data[:,0]\n",
    "test_output_data = lb.transform(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Predictions on Test Data\n",
    "\n",
    "Use [`model.predict()`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict) to predict which clothing items are depicted in the test data set. The method returns an Numpy array of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels for the unseen test data\n",
    "predictions = model.predict(test_input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review the Prediction Results\n",
    "\n",
    "Each row in this array contains a numeric score (ranging from 0 and 1) for each of the 10 classes that we trained the model on, indicating the likelihood that the depicted clothing item belongs to the class. For the first image in the test data set the predictions look as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The higher the score, the more confident the model is that the depicted clothing item belongs to the class. Calculate the maximum for each rows to determine what the predicted label is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label = [np.argmax(i) for i in predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a peek at the predicted label and the correct label for the first clothing item in the test data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Predicted label for the first clothing item: {}'.format(pred_label[0]))\n",
    "print('Correct label for the first clothing item:   {}'.format(label[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally the prediction should be correct, but your results might vary. Let's tally up the numbers for the entire test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify correctly and incorrectly classified clothing items\n",
    "\n",
    "correctly_classified = []\n",
    "incorrectly_classified = []\n",
    "index = 0\n",
    "for actual, predict in zip(label, pred_label):\n",
    "    if actual == predict:\n",
    "        correctly_classified.append(index)\n",
    "    else:\n",
    "        incorrectly_classified.append(index)\n",
    "    index += 1\n",
    "\n",
    "ccc = len(correctly_classified)\n",
    "icc = len(incorrectly_classified)\n",
    "print('Correctly classified clothing items  : {:5d} ({:=5.2f} %)'.format(ccc, ccc * 100 / (ccc + icc)))    \n",
    "print('Incorrectly classified clothing items: {:5d} ({:=5.2f} %)'.format(icc, icc * 100 / (ccc + icc)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this breakdown is useful, it doesn't provide any details as to how well the model can identify individual clothing items.\n",
    "In machine learning, a [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix) is commonly used to visualize the performance of a classification algorithm.\n",
    "\n",
    "Calculate the confusion matrix using the correct labels and predicted labels as input, using scikit-learn's [`sklearn.metrics.confusion_matrix()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) method. We then use the [seaborn](https://seaborn.pydata.org/) visualization library to display thye matrix as a heatmap.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(label, pred_label)\n",
    "\n",
    "# display confusion matrix as heatmap\n",
    "ax = sns.heatmap(conf_matrix, \n",
    "            cmap='Blues', \n",
    "            xticklabels=label_map, \n",
    "            yticklabels=label_map,\n",
    "            annot=True,\n",
    "            fmt='d')\n",
    "\n",
    "plt.xlabel('Predicted label') \n",
    "plt.ylabel('Correct label') \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Fashion-MNIST data set the output is a 10 by 10 matrix, comprising of one row and column per class. The correct predictions are located in the diagonal. The number of incorrectly classified clothing items are displayed outside that diagonal. Inspecting the output, it appears that the trained model incorrectly idenitifies quite a few clothing items as t-shirts and shirts.\n",
    "\n",
    "For illustrative purposes we'll inspect a few of the incorrectly classified clothing items. While this probably won't provide you with any useful insights, it might satisfy your curiosity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot up to max_preview clothing items that were correctly identified\n",
    "max_preview = 5\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "for index, fail_index in enumerate(incorrectly_classified[0:max_preview]):\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.subplot(4, 5, index + 1)\n",
    "    plt.imshow(np.reshape(X_test[fail_index], (28,28)), cmap=plt.cm.binary)\n",
    "    plt.title('Pred: {}, Actual: {}'.format(label_map[pred_label[fail_index]], label_map[label[fail_index]]), fontsize = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll calculate precision, recall, and accuracy to formally quantify the model performance. \n",
    "\n",
    "#### Calculate the precision scores\n",
    "\n",
    "We use scikit-learn's [`sklearn.metrics.precision_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html?highlight=precision_score#sklearn.metrics.precision_score) method to calculate the precision for each of the 10 classes, using the correct labels and predicted labels as input. The precision quantifies the ability of the classifier not to label as positive a sample that is negative. For example, if many clothing items are incorrectly classified as shirts the precision score for shirts should be lower. A value of 1 is best and 0 the worst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision scores\n",
    "precision_scores = precision_score(label, pred_label, average=None)\n",
    "\n",
    "y_pos = np.arange(len(precision_scores))\n",
    "\n",
    "plt.bar(y_pos, precision_scores, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, label_map, rotation=90)\n",
    "plt.ylabel('Precision ( --> better)')\n",
    "plt.title('Precision scores per class')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision score for shirts indicates that the model incorrectly identifies quite a few clothing items that are not shirts as shirts.\n",
    "\n",
    "#### Calculate the recall\n",
    "\n",
    "We use scikit-learn's [`sklearn.metrics.recall_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html) method to calculate the precision for each of the 10 classes, using the correct labels and predicted labels as input. The recall quantifies the ability of the classifier find all positive examples. For example, a high recall value for trousers indicates that the model does well identifying trousers. A value of 1 is best and 0 the worst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate recall score for each class\n",
    "recall_scores = recall_score(label, pred_label, average=None)\n",
    "\n",
    "# Visualize recall scores\n",
    "\n",
    "y_pos = np.arange(len(recall_scores))\n",
    "\n",
    "plt.bar(y_pos, recall_scores, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, label_map, rotation=90)\n",
    "plt.ylabel('Recall ( --> better)')\n",
    "plt.title('Recall scores per class')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the trained model isn't very good yet at correctly identifying pullovers, coats, and shirts.\n",
    "\n",
    "#### Calculate the overall accuracy\n",
    "\n",
    "We use scikit-learn's [`sklearn.metrics.acuracy_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) method to calculate the accuracy score, using the correct labels and predicted labels as input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy score\n",
    "accuracy_score(label, pred_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions\n",
    "\n",
    "Our trained model evaluation has identified a few weaknesses that have an impact on the overall performance of this model. Given the insights you could try the following to improve the model's prediction performance for poorly classified classes, such as shirts and t-shirts:\n",
    " - Tune the model hyperparameters in order to improve performance on those classes, without degrading the performance for other classes.\n",
    " - Collect more images for those classes to give the model more data to learn from.\n",
    " - Apply data augmentation approaches. For image data, this can be creating more data artificially by doing “flips”, “rotations”, playing with color, brightness, etc in order to create more and “more difficult to classify” training examples in order to allow the model to learn more with the same amount of actual data.\n",
    "\n",
    "#### Next steps\n",
    "\n",
    "- Close this notebook.\n",
    "\n",
    "\n",
    "<a id=\"authors\"></a> \n",
    "### Authors\n",
    "\n",
    "This notebook was created by the [Center for Open-Source Data & AI Technologies](http://codait.org).\n",
    "<br><br>\n",
    "\n",
    "Copyright © 2019 IBM. This notebook and its source code are released under the terms of the MIT License.\n",
    "<br><br>\n",
    "<div style=\"background:#F5F7FA; height:110px; padding: 2em; font-size:14px;\">\n",
    "<span style=\"font-size:18px;color:#152935;\">Love this notebook? </span>\n",
    "<span style=\"font-size:15px;color:#152935;float:right;margin-right:40px;\">Don't have an account yet?</span><br>\n",
    "<span style=\"color:#5A6872;\">Share it with your colleagues and help them discover the power of Watson Studio!</span>\n",
    "<span style=\"border: 1px solid #3d70b2;padding:8px;float:right;margin-right:40px; color:#3d70b2;\"><a href=\"https://ibm.co/wsnotebooks\" target=\"_blank\" style=\"color: #3d70b2;text-decoration: none;\">Sign Up</a></span><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
